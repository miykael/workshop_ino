{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8c98dd",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "The goal of this interactive demo is to show you how a machine learning model can perform regression. However, keep in mind, that the code in this notebook was simplified for the demo, and should not be used as a plug and play example for real machine learning projects.\n",
    "\n",
    "In this notebook we will explore two different types of regression models:\n",
    "\n",
    "- `Ridge` regression, using an **L2** norm (i.e. euclidean distance) to regularize its coefficients\n",
    "- `Lasso` regression, using an **L1** norm (i.e. absolute distance) to regularize its coefficients\n",
    "\n",
    "\n",
    "## The dataset\n",
    "\n",
    "For the purpose of this demo we will use the **house prices** dataset about residential homes in Ames, Iowa. As before, we will simplify the dataset slightly to keep computation low and interpretation easy.\n",
    "\n",
    "Let's go ahead and download and prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd279f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load house prices dataset\n",
    "df = pd.read_csv('house_prices.csv')\n",
    "X = df.drop(columns=['SalePrice'])\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Remove rows with missing values\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "# One-hot encode categorical and text features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Log-scale target feature, i.e. the price of the house\n",
    "y = np.log10(y)\n",
    "\n",
    "# Show 5 random rows in the dataset\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66bde5",
   "metadata": {},
   "source": [
    "Let's extract the size of the dataset and plot a value distribution of the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report size of the dataset\n",
    "print(f\"Dimension of X: {X.shape}\\nDimension of y: {y.shape}\")\n",
    "\n",
    "# Plot value distribution of target feature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y, bins=100)\n",
    "plt.title(\"House price [log10 scaled]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6d504",
   "metadata": {},
   "source": [
    "Last but not least, let's split the dataset into a training and test set, so that we can better fine tune the hyper-parameters. The split will be 80 / 20, meaning that we use 80% of the dataset as training set and 20% as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ffe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872eb91",
   "metadata": {},
   "source": [
    "## Machine learning model pipeline\n",
    "\n",
    "First things first, let's specify the type of regression model we want to use (you can choose between `Ridge` and `Lasso`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46553d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "regressor = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0baa2f6",
   "metadata": {},
   "source": [
    "Now that we know which regression model we will be using, let's also create the processing pipeline that comes before it. Such a pipeline allows us to fine-tune the hyper-parameters of the regression model, as well as explore the usefullness of different pre-processing routines.\n",
    "\n",
    "For this demo, let's explore different data scaling routines, as well as usage of a principal component analysis (PCA) step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Processing pipeline for numerical data\n",
    "numeric_preprocessor = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"pca\", PCA()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine this with the processing pipeline for categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numeric_preprocessor, X.select_dtypes(\"number\").columns),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "         X.select_dtypes(exclude=\"number\").columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Add regression model at the end of the pipeline\n",
    "pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"regressor\", regressor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0794a1",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "The last thing that we need to specify before we can train the model, is the parameter grid that we want to explore. In other words, what kind of hyper-parameter combinations do we want to explore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Create parameter grid\n",
    "param_grid = {\n",
    "    # Explore different types of scalers\n",
    "    f\"prep__num__scaler\": [None, StandardScaler()],\n",
    "    \n",
    "    # Explore usefullness of a PCA\n",
    "    f\"prep__num__pca\": [None, PCA(0.99)],\n",
    "    \n",
    "    # Fine-tune regressor hyper-parameter 'alpha'\n",
    "    \"regressor__alpha\": np.logspace(-5, 5, 11),\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"The grid search will explore {len(ParameterGrid(param_grid))} paramter combinations.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a61607",
   "metadata": {},
   "source": [
    "Now, everything is ready to train. So let's go ahead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e635013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Put parameter grid and regression model into GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid, cv=2, n_jobs=-1, verbose=2, return_train_score=True\n",
    ")\n",
    "\n",
    "# Train regression model on training data\n",
    "res = grid.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cee7f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Important note:</strong> Potential <code>RuntimeWarnings</code> can be ignored!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896cd91f",
   "metadata": {},
   "source": [
    "## Grid search exploration\n",
    "\n",
    "Once the parameter grid was explored, let's have a look at the parameter combinations that lead to the best models (i.e. the models with the highest performance scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5801bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean out results table of the parameter grid\n",
    "cv_results = pd.DataFrame(res.cv_results_)\n",
    "cv_results = cv_results.iloc[\n",
    "    :, ~cv_results.columns.str.contains(\"time|split[0-9]*|rank|params\")\n",
    "]\n",
    "new_columns = [c.split(\"param_\")[1] if \"param_\" in c else c for c in cv_results.columns]\n",
    "new_columns = [c.split(\"prep__\")[1] if \"prep__\" in c else c for c in new_columns]\n",
    "cv_results.columns = new_columns\n",
    "\n",
    "# Sort results table according to best score\n",
    "cv_results = cv_results.sort_values(\"mean_test_score\", ascending=False)\n",
    "\n",
    "# Visualize top parameter combinations and scores\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8e903",
   "metadata": {},
   "source": [
    "Let's have a closer look at this table and the different grid-search parameter combinations by plotting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_grid_search\n",
    "plot_grid_search(param_grid, cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4a8da3",
   "metadata": {},
   "source": [
    "## Model performance investigation\n",
    "\n",
    "Depending on what we see in the previous table and figures, we might want to readjust our grid-search and retrain the model. But once we're happy with what we did and think we identified the \"best\" optimal model, we can go ahead and test it against a new dataset and explore the relevance of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec504874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best estimator with the best hyper parameter\n",
    "best_estimator = grid.best_estimator_\n",
    "\n",
    "# Fit this best estimator once more, but this time using the full training set\n",
    "_ = best_estimator.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01024b82",
   "metadata": {},
   "source": [
    "Now we have the final model, the model that we potentially would want to deploy on our devices. So let's see how well it would perform on the withheld test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance on training and test set\n",
    "score_tr = best_estimator.score(X_tr, y_tr)\n",
    "score_te = best_estimator.score(X_te, y_te)\n",
    "\n",
    "print(f\"Prediction score on train data: {score_tr:.3f}\\n\\\n",
    "Prediction score on test data:  {score_te:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a731cf",
   "metadata": {},
   "source": [
    "The training and the test scores are very close, that is great news! This implies that our model probably is able to generalize it's performance onto a new and unseen dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a341a",
   "metadata": {},
   "source": [
    "## Coefficient exploration\n",
    "\n",
    "A great way to better understand a model's performance is to look at its coefficients. However, it is **important to highlight that the biggest coefficients do not always have to be the most important ones**.\n",
    "\n",
    "So what are our model's coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of regression model coefficient\n",
    "plt.figure(figsize=(15, 25))\n",
    "sort_idx = np.argsort(best_estimator[\"regressor\"].coef_)\n",
    "plt.barh(best_estimator.feature_names_in_[sort_idx],\n",
    "         best_estimator[\"regressor\"].coef_[sort_idx])\n",
    "plt.ylim(-1, sort_idx.max() + 1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b8ef3",
   "metadata": {},
   "source": [
    "Now, to better understand **which coefficients are really important** for the prediction, we can deploy a **permutation approach**. In short, we will run the model prediction multiple times, but for each iteration we shuffle one of the features randomly. The idea is the following, if a feature is important, than the random shuffling of this feature should reduce the overall performance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Reshuffle each feature 5 times and compute the drop of the performance score\n",
    "result = permutation_importance(\n",
    "    best_estimator, X_te, y_te, n_repeats=5, random_state=0, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67e8ef",
   "metadata": {},
   "source": [
    "Once everything is computed, we can go ahead and plot the feature importance for each feature. The further away this feature importance score is from zero, the more important is its role for a good model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8829211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model performance\n",
    "plt.figure(figsize=(15, 25))\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T, vert=False, labels=X_te.columns[sorted_idx]\n",
    ")\n",
    "plt.title(\"Feature importances score (test set)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc1b66",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "    <p></p>\n",
    "Change the <code>regressor</code> parameter to <code>Lasso()</code> and rerun all the cells after that. How does this effect the final score? How does this change the importance and size of the model coefficients?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
