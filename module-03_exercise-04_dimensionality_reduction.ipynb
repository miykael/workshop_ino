{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "The goal of this interactive demo is to show you how a machine learning model can perform dimensionality reduction. However, keep in mind, that the code in this notebook was simplified for the demo, and should not be used as a plug and play example for real machine learning projects.\n",
    "\n",
    "In this notebook we will explore three different types of dimensionality reduction models:\n",
    "\n",
    "- Projection based\n",
    "- Manifold based\n",
    "- Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "For the purpose of this demo we will use the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. This dataset contains 60'000 grayscale images (of size 28 x 28 pixels) of 10 distinct target classes:\n",
    "\n",
    "1. T-shirt/top\n",
    "2. Trouser\n",
    "3. Pullover\n",
    "4. Dress\n",
    "5. Coat\n",
    "6. Sandal\n",
    "7. Shirt\n",
    "8. Sneaker\n",
    "9. Bag\n",
    "10. Ankle boot\n",
    "\n",
    "So let's go ahead and download and prepare the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant tensorflow packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load dataset, already pre-split into train and test set\n",
    "(X_tr, y_tr), (X_te, y_te) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Reshape data to 2D array\n",
    "X_tr = X_tr.reshape(len(X_tr), -1)\n",
    "X_te = X_te.reshape(len(X_te), -1)\n",
    "\n",
    "# Specify target class labels\n",
    "labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "          \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "# Report shape of dataset\n",
    "print(\"X_tr shape:\", X_tr.shape)\n",
    "print(\"X_te shape:\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first few hundered images of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create image collage\n",
    "img_collage = np.concatenate(\n",
    "    [np.concatenate(\n",
    "            [X_tr[idx + jdx * 25].reshape(28, 28) for idx in range(25)], axis=1\n",
    "        ) for jdx in range(10)])\n",
    "\n",
    "# Plot image collage\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img_collage, cmap=\"binary\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection based dimensionaly reduction\n",
    "\n",
    "Now that the data is ready, let's go ahead explore a projection based dimensionality reduction method, the **principal component analysis** (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create PCA model\n",
    "pca = PCA()\n",
    "\n",
    "# Train and apply PCA model to the training data\n",
    "X_tr_pca = pca.fit_transform(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the PCA model was trained and the data was projected to a lower dimensional space, let's take a look at how the 10 target classes distribute over those dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_2d_grid\n",
    "plot_2d_grid(X_tr_pca, y_tr, labels, d1=0, d2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "    <p></p>\n",
    "Change the <code>d1</code> and <code>d2</code> parameters to any other values between 0 and 19 to see how the target classes distribute over the first 20 dimensions of this low-dimensional PCA-space.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_pca_decomposition\n",
    "plot_pca_decomposition(X_tr, y_tr, n_dim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "    <p></p>\n",
    "Change the <code>n_dim</code> value to anything between 0 and 783 to see the data compression effect of the dimensionality reduction approach.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold based dimensionaly reduction\n",
    "\n",
    "Next up is the exploration of the **manifold** based dimensionaly reduction. There are a lot of different routines how such a manifold can be identified and the data than can be mapped onto this manifold. Let's take a look at one of them, called Uniform Manifold Approximation and Projection (UMAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(n_components=4, min_dist=0.8, n_jobs=-1)\n",
    "X_tr_umap = umap.fit_transform(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's have a look at how the data is distributed over the low dimensionsinal space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_grid(X_tr_umap, y_tr, labels, d1=0, d2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "  <h2>Exercise</h2>\n",
    "    <p></p>\n",
    "Change the <code>d1</code> and <code>d2</code> parameters to any other values between 0 and 4 to see how the target classes distribute over the first 4 dimensions of this low-dimensional PCA-space.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "Last but not least, let's look at a dimensionality reduction approach that uses deep learning, called **autoencoder**. To be more precise, we will use a sub-category of autoencoders, called **variational autoencoder (VAE)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and rescale data to prepare it for the autoencoder model\n",
    "mnist_digits = X_tr.reshape(-1, 28, 28, 1).astype(\"float32\") / 255\n",
    "\n",
    "# Create variational autoencoder (VAE)\n",
    "from utils import get_variational_autoencoder\n",
    "vae = get_variational_autoencoder(n_dim=2)\n",
    "\n",
    "# Train variational autoencoder model\n",
    "vae.fit(mnist_digits, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the autoencoder is trained, we can pass data through it and extract the low-dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute low-dimensional data representation\n",
    "X_tr_vae = vae.encoder.predict(mnist_digits)[0]\n",
    "\n",
    "# Plot low-dimensional data representation\n",
    "plot_2d_grid(X_tr_vae, y_tr, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
